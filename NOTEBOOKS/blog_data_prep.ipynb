{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "covered-disclosure",
   "metadata": {},
   "source": [
    "# Blog data preparation\n",
    "\n",
    "## Environment prep and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neutral-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "otherwise-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "naughty-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-companion",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "This data is provided by https://u.cs.biu.ac.il/~koppel/BlogCorpus.htm. [1] It is an academic dataset of blogger metadata and blog contents. We can either stick with the original dataset in its `.xml` form or we can use [Kaggle's version](https://www.kaggle.com/rtatman/blog-authorship-corpus). The original data has a host of different encodings, which makes it necessary to detect the correct encoding before reading in the file much of the time, and even then we still fail to read over 30 files. Furthermore, the original data address has recently changed without providing a new location. We therefore recommend the Kaggle approach. However, the following code is preserved in case anyone wants to process the original dataset by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-marshall",
   "metadata": {},
   "source": [
    "## Prepare the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "structured-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_entries(filename, min_length=1):\n",
    "    \"\"\"Read a blogfile and record entries with more words than min_length\n",
    "    \n",
    "    The compilers of this data left the blog files in an assortment of different encodings. \n",
    "    Short of hard-coding the exact encoding for each file, the only solution seems to be\n",
    "    to detect them dynamically at file read time and then attempt to use that encoding.\n",
    "    This should not ordinarily be done, since it is slow and dumb.\n",
    "    \"\"\"\n",
    "    vals = filename.split(\"/\")[-1].split(\".\")\n",
    "    base_dict = {\"blogger_id\": vals[0], \n",
    "                 \"sex\": vals[1],\n",
    "                 \"age\": vals[2],\n",
    "                 \"topic\": vals[3],\n",
    "                 \"sign\": vals[4],\n",
    "                }\n",
    "    valid_posts = []\n",
    "    try: # start with default encoding\n",
    "        with open(filename, \"r\") as infile:\n",
    "            content = infile.read()\n",
    "    except: # if that fails, try to detect the encoding\n",
    "        try:\n",
    "            with open(filename, \"rb\") as infile:\n",
    "                bcontent = infile.read()\n",
    "                detect = chardet.detect(bcontent)\n",
    "                content = bcontent.decode(encoding=detect['encoding'])\n",
    "        except: # if that fails, skip the file\n",
    "            print(f\"failed on {filename}\")\n",
    "            return valid_posts\n",
    "            \n",
    "    bs_content = bs(content, \"lxml\")\n",
    "    dates = bs_content.find_all(\"date\")\n",
    "    posts = bs_content.find_all(\"post\")\n",
    "    for i in range(len(posts)):\n",
    "        text = posts[i].text.strip()\n",
    "        if len(text.split(\" \")) >= min_length:\n",
    "            post_dict = base_dict.copy()\n",
    "            post_dict[\"date\"] = dates[i].text\n",
    "            post_dict[\"post_content\"] = text\n",
    "            valid_posts.append(post_dict)\n",
    " \n",
    "    return valid_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powered-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment to run\n",
    "# ! wget http://www.cs.biu.ac.il/~koppel/blogs/blogs.zip\n",
    "# ! unzip blogs.zip -d ../Data -q\n",
    "# ! rm blogs.zip\n",
    "# df_columns = [\"blogger_id\", \"sex\", \"age\", \"topic\", \"sign\", \"date\", \"post_content\"]\n",
    "# df_entries = []\n",
    "# for filename in tqdm(glob(\"../Data/blogs/*.xml\")):\n",
    "#     df_entries += get_blog_entries(filename)\n",
    "# df = pd.DataFrame(df_entries, columns=df_columns)\n",
    "# with open(\"../Data/blogs_df.pkl\", \"wb\") as outfile:\n",
    "#     pickle.dump(df, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-horizontal",
   "metadata": {},
   "source": [
    "## Prepare the Kaggle version\n",
    "First, sign into Kaggle and download the data from https://www.kaggle.com/rtatman/blog-authorship-corpus/, saving it in the `../Data` directory as `blogtext.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "plastic-taxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open '../Data/blogtext.csv' for reading: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! head ../Data/blogtext.csv -n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "labeled-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf = pd.read_csv(\"../Data/blogtext.csv\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rural-metallic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681279</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  I could write some really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681280</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  'I have the second yeast i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681281</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan,  Your 'boyfriend' is fuckin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681282</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Dear Susan:    Just to clarify, I am as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681283</th>\n",
       "      <td>1713845</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Student</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>01,July,2004</td>\n",
       "      <td>Hey everybody...and Susan,  You might a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681284 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id gender  age              topic      sign          date  \\\n",
       "0       2059027   male   15            Student       Leo   14,May,2004   \n",
       "1       2059027   male   15            Student       Leo   13,May,2004   \n",
       "2       2059027   male   15            Student       Leo   12,May,2004   \n",
       "3       2059027   male   15            Student       Leo   12,May,2004   \n",
       "4       3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "...         ...    ...  ...                ...       ...           ...   \n",
       "681279  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "681280  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "681281  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "681282  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "681283  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "\n",
       "                                                     text  \n",
       "0                  Info has been found (+/- 100 pages,...  \n",
       "1                  These are the team members:   Drewe...  \n",
       "2                  In het kader van kernfusie op aarde...  \n",
       "3                        testing!!!  testing!!!            \n",
       "4                    Thanks to Yahoo!'s Toolbar I can ...  \n",
       "...                                                   ...  \n",
       "681279         Dear Susan,  I could write some really ...  \n",
       "681280         Dear Susan,  'I have the second yeast i...  \n",
       "681281         Dear Susan,  Your 'boyfriend' is fuckin...  \n",
       "681282         Dear Susan:    Just to clarify, I am as...  \n",
       "681283         Hey everybody...and Susan,  You might a...  \n",
       "\n",
       "[681284 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-comment",
   "metadata": {},
   "source": [
    "Well, this version definitely preserved the text I couldn't read due to encoding issues in the original data. We'll roll with this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "virgin-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_text(text_string):\n",
    "    '''Tokenize a text string.'''\n",
    "    tokenized_text = nltk.casual_tokenize(text_string.translate(str.maketrans(\n",
    "        '', \n",
    "        '', \n",
    "        string.punctuation,\n",
    "        )),\n",
    "        preserve_case=False,strip_handles=True)\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "french-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf['tokens'] = kdf.text.apply(prep_text)\n",
    "with open(\"../Data/blog_df_casual_tokens.pkl\", \"wb\") as outfile:\n",
    "    pickle.dump(kdf, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-terrain",
   "metadata": {},
   "source": [
    "# References\n",
    "1. J. Schler, M. Koppel, S. Argamon and J. Pennebaker (2006). Effects of Age and Gender on Blogging in Proceedings of 2006 AAAI Spring Symposium on Computational Approaches for Analyzing Weblogs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
